%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document


% MYTHINGS
\usepackage{amssymb,amsmath, amsfonts,color}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newcommand{\R}{\mathbb{R}}

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
GP-based Model Predictive Control*
}


\author{Dimitrios Gkoutzos$^{1}$, Luzia Knödler$^{2}$ and Lucas Rath$^{3}$% <-this % stops a space
\thanks{*Project within the course Statistical Learning and Stochastic Control, University of Stuttgart, \today.}% <-this % stops a space
\thanks{$^{1}$Dimitrios Gkoutzos is a student of the Master study programm Engineering Cybernetics, University of Stuttgart,
        {\tt\small albert.author@papercept.net}}%
\thanks{$^{2}$Luzia Knödler is a student of the Master study program Engineering Cybernetics, University of Stuttgart,
        {\tt\small b.d.researcher@ieee.org}}%
\thanks{$^{3}$Lucas Rath is a student of the Master study program Engineering Cybernetics, University of Stuttgart, and of the Master study program Systems, Control and Mechatronics, Chalmers University of Technology,
        {\tt\small b.d.researcher@ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Describe topic and relevance in a few sentences so that the reader is motivated to
read the whole paper.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
Model predictive control (MPC) is a popular control strategy which uses a dynamic plant model to obtain the control input that optimizes future reactions of the plant~\cite{kocijan2004gaussian}. The performance of MPC depends highly on how well the model captures the dynamics of the plant~\cite{kabzan2019learning}. But the identification of such an \textit{a priori} model can be challenging and the dynamics of the plant could also change during the application~\cite{kabzan2019learning,ostafew2014learning}. Therefore, a simple and fixed nominal model of the plant can be used in combination with a learned disturbance model. The disturbance model represents the error between the observed behaviour of the plant and the behaviour of the nominal model~\cite{ostafew2014learning}. It can be modelled as a Gaussian Process (GP) regression which is a probabilistic, non-parametric model~\cite{kocijan2004gaussian}. GPs have the advantage of characterizing the prediction uncertainities~\cite{kocijan2004gaussian}. The mean estiamte of a GP can also be used to model the full dynamics of the plant and not only the model error. This approach was applied to a cart pole swing-up environment and an autonomous racing task in \cite{van2017online}. To reduce high computational costs they choose sparce spectrum GPs. Kocijan et al.~\cite{kocijan2004gaussian} use an offline-identified GP model instead. Another alternative is the generation of local GPs (LGPs) where for each subspace of the GP input space different GPs are identified. While Nguyen-Tuong et al.~\cite{nguyen2009local} and Meier et al.~\cite{meier2014efficient} identify many LGPs, Ostafew et al.~\cite{ostafew2014learning} compute one single LGP based on data within a sliding window. Other applications of GPs in a MPC framework are .
 \\
In this report we present the results of our project within the course ``Statistical Learning and Stochastic Control''. First, our literature research on GP-based MPC is summarized. Then a short introduction to the theory of MPC and GPs is given. Later, two examples which's  implementation was part of the project are introduced in Section~\ref{main_results} and the results are discussed in Section~\ref{examples}.\\
  \\
We start by defining the used noation below.

Introduce topic and describe motivation and relevance of problem/topic.

In this paper we give an introduction to the results presented in paper(s) \cite{Bro-14}.
We present the main results, discuss ideas and illustrate the results with simulations.\\

Notation. Define notation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BACKGROUND}
In this section a revision of GPs for our application and necessary background information on MPC are presented. The revison of GPs follows Kabzan et al.~\cite{kabzan2019learning} as well as Rasmussen and Williams~\cite{williams2006gaussian}. \\

As mentioned in the Introduction, a GP is used to identify the disturbance $d_{true}$, which describes the error between the nominal plant dynamics $f_{nom}$ and the true dynamics $f_{true}$. Thus, the true system equations are given by
\begin{align}
\begin{split}
x_{k+1} &= f_{true}(x_k,u_k) \\
        &=  f_{nom}(x_k,u_k) + B_d\big(d_{true}(z_k)+ w\big),
\end{split}
\end{align}
with $z_k = B_z x_k$ ($B_z \in \mathcal{n_z \times n}$ and $w \sim \mathcal{N}(0,\Sigma_w)$  the gaussian measurement noise, where $\Sigma_w= diag(\sigma_1^2, \cdots ,\sigma_{n_d}^2)$.
The disturbance $d = d_{true}(z_k) + w_k$ is identified using input and output data pairs $(z_k,y_k=d_{true}(z_k)+w_k)$ which are saved in a dictionary $\mathcal{D}$ of length $m$
\begin{align}
\begin{split}
\mathcal{D} = \{Z &=[z_1, \cdots, z_m] \in \R^{n_z \times m} , \\
                Y &=[y_{1},\cdots,y_{m}]\in \R^{n_d \times m} \}.
\end{split}
\end{align}
If $m>m_{max}$, the dictionary is updated by removing the oldest data pair.\\
Each output dimension $a \in \{1, \cdots, n_d\}$ is treated as a different GP with the kernel $k^a$, which results in the posterior distribution mean $\mu^a(z)$ and variance $\Sigma^a(z)$
\begin{align}
\mu^a(z) &= k_{zZ}^a( K_{ZZ}^a +I \sigma_a)^{-1}[Y]_{.,i},\\
\Sigma^a(z) &= k_{zz}^a-k_{zZ}^a ( K_{ZZ}^a +I \sigma_a)^{-1} k_{Zz}^a
\end{align}
in dimension $a$ for a test point $z$.
The expressions $k_{zz}^a$, $ k_{zZ}^a$, $k_{Zz}^a$ and $K_{ZZ}^a$ are compact notations for $k^a(z,z) \in \R$, $[k_{zZ}^a]_j =k^a(z,z_j)$, $[k_{Zz}^a]_j =k^a(z_j,z)$ and $[K_{ZZ}^a]_{ij} = k^a(z_i,z_j)$, respectively. It holds $k_{Zz}^a=(k_{zZ}^a)^T \in \R^m$.\\
For each output dimension $a$ we make use of the squared exponentional kernel given by
\begin{equation}
k^a(z,\bar{z}) = \sigma_{f,a}^2 \exp(-0.5(z-\bar{z})^T M^{-1} (z-\bar{z})),
\end{equation}
where $\sigma_{f,a}^2$ and $M$ are the squared output variance and the positive diagonal length scale matrix, respectively.
The practical implementation of Gaussian process regression from page 19 of Rasmussen and Williams~\cite{williams2006gaussian} which uses the Cholesky factorization to address the matrix inversion is applied. This results in the following algorithm
\begin{align}
L^a &= \text{cholesky}(K(Z,Z) + \sigma_n(a,a)^2I)\\
\alpha^a &= L^T\backslash(L \backslash Y(:,a)),
\end{align}
where $[K(Z,Z)]_{ij}=k(z_i,z_j)$ with $z_i, z_j \in Z$.
Thus, the predictive mean and variance are given by
\begin{align}
\mu_y^a&=K(z,Z)^T\alpha^a\\
\Sigma_y^a&=k(z,z)-v^Tv,
\end{align}
with $v=L/K(z,Z)$.\\
Combining the GPs of each dimension results in the multivariate GP approximation 
\begin{equation}
d(z)\sim \mathcal{N}(\mu^d(z),\Sigma^d(z)),
\end{equation}
where the mean $\mu^d(z) \in \mathcal{R}^{n_d}$ and the variance $\Sigma^d(z)~\in~\mathcal{R}^{n_d \times n_d}$ are given by
\begin{align}
\mu^d(z) &= [\mu^1(z),\cdots, \mu^{n_d}(z)]^T,\\
\Sigma^d(z) &= \text{diag}([\Sigma^1(z),\cdots, \Sigma^{n_d}(z)]).
\end{align}
The model considered for control including the identified disturbance $d$ is given by
\begin{equation}
x_{k+1} = f_{nom}(x_k,u_k) + B_d d(z_k).
\end{equation}
 \\
Model predictive control (MPC), receding  horizon  control or moving horizon control are all names for a control strategy which predicts the future dynamic behaviour within a finite prediction horizion and chooses the control input such that a perfomance functional is minimized~\cite{allgeowernonlinear}. Since the predicted behaviour is not equal to the system behaviour due to disturbances and model-plant mismatch, only the first input of the computed control input sequence is applied~\cite{allgeowernonlinear}. Using the new measurement one sampling time later, the procedure is repeated to find a new control sequence within the receding horizon.\\
Evaluating the GP model $d(x_k,u_k)$ results in a stochastic distribution, which leads to a stochastic distribution of the state $x$. The distribution at each prediction step is assumed to be Gaussian with $x_k \sim \mathcal{N}(\mu^x_k,\Sigma^x_k)$. To evaluate the uncertainity over the prediction horizon $N$ the mean and variance of $x$ are propagated forward which results in
\begin{align}
\mu^x_{k+1}&= f_{nom}(\mu^x_k,u_k)+B_d \mu^d(\mu^x_k,u_k)\\
\Sigma^x_{k+1} &= ????.
\end{align}
For more information on the propagation see ???? Appendix.
Thus, the MPC problem is given by
\begin{align}
\min_{\tilde{u}} &\big(\sum_{k=0}^{N-1} f_o(t_k,\mu^x_k,\Sigma^x_k,\tilde{u}_k,r(t))\big) + f_{end}(t_N,\mu^x_N,\Sigma^x_N,r(t_N))\\
&\mu^x_0 = x(t)\\
&\mu^x_{k+1}= f_{nom}(\mu^x_k,\tilde{u}_k)+B_d \mu^d_k\\
&\Sigma^x_{k+1}=\nabla^T  f_{nom}(\mu^x_k,\tilde{u}_k),\Sigma_{xdw} \nabla f_{nom}(\mu^x_k,\tilde{u}_k),\\
&\mu^x_k \in \mathcal{X},\\
&u_k \in \mathcal{U},
\end{align}
where $\tilde{u}(\dot):[t,t+N] \rightarrow \mathcal{U}$ and $\tilde{u}_k$ refers to the k-th element of $\tilde{u}$. The reference trajectory is given by $r(t)$. The input and state constraint sets $\mathcal{U}$ and $\mathcal{X}$ can be defined as box constraints according to Allgöwer et al.~\cite{allgeowernonlinear}
\begin{align}
\mathcal{U} &= \{u \in \mathcal{R}^p|u_{min}\leq u \leq u_{max}\},\\
\mathcal{X} &= \{u \in \mathcal{R}^n|x_{min}\leq x \leq x_{max}\}.
\end{align}
According to the control problem, a cost function $f_o$ and the final cost $f_{end}$ are defined. The cost functions, which were used during this project, are further described for each example in Section~\ref{main_results}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MAIN RESULTS}\label{main_results}

Ideas, theorems, proofs and discussions .....


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXAMPLES}\label{examples}

Show and discuss simulation examples etc....



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSIONS}

Summarize the main points (with more details than in the preceding introduction).
The paper should not be between 4 and 8 pages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}

Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{mybib}

%\begin{thebibliography}{99}
%\end{thebibliography}

\end{document}
